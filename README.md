# NLP

# Data Preprocessing


# Representation Learning / Pre-Training

# Downstream NLP / Model Alignment / Instruction Tuning
1. [UniTask Downstream Task](https://github.com/khetansarvesh/NLP/tree/main/unitask_downstream_nlp)
   - No one does this anymore with the rise of one single model that can do multiple tasks
3. [MultiTask Downstream Task](https://github.com/khetansarvesh/NLP/tree/main/multitask_downstream_task)

# Preference Alignment / Post-Training
You can read complete details about this [here](https://medium.com/p/0b67777fa7af/edit)

# Resources Used to Develop This
1. [Standford CS224N - 2016](https://www.youtube.com/playlist?list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z)
2. [Standford CS224N - 2021](https://www.youtube.com/watch?v=rmVRLeJRkl4&list=PLoROMvodv4rMFqRtEuo6SGjY4XbRIVRd4)
3. [Standford CS224N - 2023](https://www.youtube.com/watch?v=LWMzyfvuehA&list=PL613dYIGMXoZ0Wl6tj8VvHaFUTAWE8fbW)
4. [Standford CS224D](https://www.youtube.com/playlist?list=PLlJy-eBtNFt4CSVWYqscHDdP58M3zFHIG)
5. [Speech and Language Processing Book](https://web.stanford.edu/~jurafsky/slp3/)
