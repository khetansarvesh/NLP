# NLP

# Representation Learning
Before performing any NLP Task it is important to convert natural language into its equivalent numerical form so that we can feed it into the model because computers cannot understand languages. There are numerous ways to do this and is an active research area, please refer to my notes linked below (recommended read) which has been collect by extensive literature survey of 2 months to understand some of the SOTA techniques like Word2Vec, BERT, GPT ... to do this.

Notes: https://drive.google.com/drive/folders/1xIgG-IPXLbB8Q7L7lVAspF824WkpZNbz?usp=sharing

# Natural Language Understanding (NLU) Task
There are several NLP task of which one is NLU task.This task includes sentence level classification problems or token/word level classification problems

## *Sentence Level Classification Problems*
Please refer to following link which contains notes explaining how to handle this problem and 3 notebooks

   Notes : https://drive.google.com/drive/folders/1k0DjnHjitHRpmz-HoeFuMQ1kU-V8taYw?usp=sharing
   
   Notebook1 : Sentimental Analysis of Movie Review without joint training https://colab.research.google.com/drive/1rNqEkn4k3g56oiTf1nWXiypHHWdFkHhZ?usp=sharing
   
   Notebook2 : Sentimental Analysis of Movie Review using joint training https://colab.research.google.com/drive/1y938G9UPNT20fLfAKcsIcLrcsos1_YZV?usp=sharing
   
   Notebook3 : Toxic Comment Classification Problem by fine tuning pre-trained DistilBERT Model https://drive.google.com/file/d/1ZSjKyq1hCTopg3NHivnLo0_3vi_2UO1d/view?usp=sharing
   
## *Word Level Classification Problems*
currently notes of this is under making, will link it once completed
   
