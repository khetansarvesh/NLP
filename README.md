# NLP

# Data Preprocessing


# Representation Learning / Pre-Training

# UniTask Downstream NLP
- Here we make different models for different types of tasks. You can learn more about this [here](https://github.com/khetansarvesh/NLP/tree/main/unitask_downstream_nlp)
- No one does this anymore with the rise of one single model that can do multiple tasks

# MultiTask Downstream NLP
   - Here we create one single model which can handle multiple tasks, this is called Model Alignment / Instruction Tuning. You can learn more about how to create such a model [here](https://github.com/khetansarvesh/NLP/tree/main/multitask_downstream_task)
   - [Preference Alignment / Post Training](https://medium.com/p/0b67777fa7af/edit)
   -  

# Resources Used to Develop This
1. [Standford CS224N - 2016](https://www.youtube.com/playlist?list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z)
2. [Standford CS224N - 2021](https://www.youtube.com/watch?v=rmVRLeJRkl4&list=PLoROMvodv4rMFqRtEuo6SGjY4XbRIVRd4)
3. [Standford CS224N - 2023](https://www.youtube.com/watch?v=LWMzyfvuehA&list=PL613dYIGMXoZ0Wl6tj8VvHaFUTAWE8fbW)
4. [Standford CS224D](https://www.youtube.com/playlist?list=PLlJy-eBtNFt4CSVWYqscHDdP58M3zFHIG)
5. [Speech and Language Processing Book](https://web.stanford.edu/~jurafsky/slp3/)
