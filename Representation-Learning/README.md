# Representation Learning
Before performing any NLP Task it is important to convert natural language into its equivalent numerical form so that we can feed it into the model because computers cannot understand languages. There are numerous ways to do this and is an active research area, please refer to my notes linked below (recommended read) which has been collect by extensive literature survey of 2 months to understand some of the SOTA techniques like Word2Vec, BERT, GPT ... to do this.

Notes: https://drive.google.com/drive/folders/1Qyan1BEMC62uibJkjckfeKXTMeqJ5Vdw?usp=sharing